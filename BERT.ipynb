{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Izhevskaya[homework]BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandraizhevskaya/Psh-psh/blob/master/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO_wCxS951bT",
        "colab_type": "text"
      },
      "source": [
        "# Homework\n",
        "\n",
        "Привет! В этой домашнем задании ты научишься обучении модели BERT. На семинаре был разобран код модели, здесь же посмотрим на то, как надо обработать данные, чтобы на них модель могла учиться. \n",
        "\n",
        "Замечания по выполнению задания:\n",
        "\n",
        "- Код внутри блока `<DON'T TOUCH THIS!>` используется для проверки задания, его нельзя трогать. \n",
        "\n",
        "- Внутри блока `<YOUR CODE>` может больше кода, чем там показано изначально.\n",
        "\n",
        "- От задания требуется написания небольшого отчета в конце.\n",
        "\n",
        "\n",
        "Для начала загрузи нужные библиотеки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dq4NkRu_u3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers catalyst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Wzln5lKR9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install alchemy-catalyst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlHnoGZN6OKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import sys\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset\n",
        "\n",
        "import transformers\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.callbacks import AccuracyCallback, SchedulerCallback, F1ScoreCallback\n",
        "from catalyst.utils import set_global_seed, prepare_cudnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmlqBOSO7a5L",
        "colab_type": "text"
      },
      "source": [
        "Внизу идет технический код, который нужен для загрузки датасетов. Его можно уменьшить, выбрав только некоторые из них. Для того, что бы зачесть задание, надо выбрать не менее двух задач, для хотя бы одной из которых нужно использовать два предложения(ответ и вопрос, два предложения и прочее). Подробнее про датасеты [здесь](https://gluebenchmark.com/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4H6_6zgnfRQR",
        "colab": {}
      },
      "source": [
        "TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\"]\n",
        "TASK2PATH = {\n",
        "    \"CoLA\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4\",\n",
        "    \"SST\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\",\n",
        "    \"MRPC\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc\",\n",
        "    \"QQP\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP.zip?alt=media&token=700c6acf-160d-4d89-81d1-de4191d02cb5\",\n",
        "    \"STS\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5\",\n",
        "    \"MNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce\",\n",
        "    \"SNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df\",\n",
        "    \"QNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601\",\n",
        "    \"RTE\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb\",\n",
        "    \"WNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf\",\n",
        "}\n",
        "\n",
        "MRPC_TRAIN = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\"\n",
        "MRPC_TEST = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt\"\n",
        "\n",
        "data_dir = \"data/\"\n",
        "max_seq_length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O8Y-go7czun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_extract(task, data_dir):\n",
        "    print(\"Downloading and extracting %s...\" % task)\n",
        "    data_file = \"%s.zip\" % task\n",
        "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
        "    with zipfile.ZipFile(data_file) as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(data_file)\n",
        "    print(\"\\tCompleted!\")\n",
        "\n",
        "def format_mrpc(data_dir, path_to_data):\n",
        "    print(\"Processing MRPC...\")\n",
        "    mrpc_dir = os.path.join(data_dir, \"MRPC\")\n",
        "    if not os.path.isdir(mrpc_dir):\n",
        "        os.mkdir(mrpc_dir)\n",
        "    if path_to_data:\n",
        "        mrpc_train_file = os.path.join(path_to_data, \"msr_paraphrase_train.txt\")\n",
        "        mrpc_test_file = os.path.join(path_to_data, \"msr_paraphrase_test.txt\")\n",
        "    else:\n",
        "        print(\"Local MRPC data not specified, downloading data from %s\" % MRPC_TRAIN)\n",
        "        mrpc_train_file = os.path.join(mrpc_dir, \"msr_paraphrase_train.txt\")\n",
        "        mrpc_test_file = os.path.join(mrpc_dir, \"msr_paraphrase_test.txt\")\n",
        "        urllib.request.urlretrieve(MRPC_TRAIN, mrpc_train_file)\n",
        "        urllib.request.urlretrieve(MRPC_TEST, mrpc_test_file)\n",
        "    assert os.path.isfile(mrpc_train_file), \"Train data not found at %s\" % mrpc_train_file\n",
        "    assert os.path.isfile(mrpc_test_file), \"Test data not found at %s\" % mrpc_test_file\n",
        "    urllib.request.urlretrieve(TASK2PATH[\"MRPC\"], os.path.join(mrpc_dir, \"dev_ids.tsv\"))\n",
        "\n",
        "    dev_ids = []\n",
        "    with open(os.path.join(mrpc_dir, \"dev_ids.tsv\"), encoding=\"utf8\") as ids_fh:\n",
        "        for row in ids_fh:\n",
        "            dev_ids.append(row.strip().split(\"\\t\"))\n",
        "\n",
        "    with open(mrpc_train_file, encoding=\"utf8\") as data_fh, open(\n",
        "        os.path.join(mrpc_dir, \"train.tsv\"), \"w\", encoding=\"utf8\"\n",
        "    ) as train_fh, open(os.path.join(mrpc_dir, \"dev.tsv\"), \"w\", encoding=\"utf8\") as dev_fh:\n",
        "        header = data_fh.readline()\n",
        "        train_fh.write(header)\n",
        "        dev_fh.write(header)\n",
        "        for row in data_fh:\n",
        "            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n",
        "            if [id1, id2] in dev_ids:\n",
        "                dev_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
        "            else:\n",
        "                train_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
        "\n",
        "    with open(mrpc_test_file, encoding=\"utf8\") as data_fh, open(\n",
        "        os.path.join(mrpc_dir, \"test.tsv\"), \"w\", encoding=\"utf8\"\n",
        "    ) as test_fh:\n",
        "        header = data_fh.readline()\n",
        "        test_fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n",
        "        for idx, row in enumerate(data_fh):\n",
        "            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n",
        "            test_fh.write(\"%d\\t%s\\t%s\\t%s\\t%s\\n\" % (idx, id1, id2, s1, s2))\n",
        "    print(\"\\tCompleted!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4hNWuZ5okuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASKS = [\"QQP\", \"SST\", \"MRPC\"] # Или можно просто сюда вписать те датасеты, которые ты выбрал.\n",
        "\n",
        "for task in TASKS:\n",
        "    if task == \"MRPC\":\n",
        "        format_mrpc(data_dir, None)\n",
        "    else:\n",
        "        download_and_extract(task, data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5S3iSoK8LOG",
        "colab_type": "text"
      },
      "source": [
        "Загрузи один из выбранных датасет с помощью Pandas(не обязательно через него, но так проще) и посмотри на него."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeH7ZgNdLq54",
        "colab_type": "text"
      },
      "source": [
        "Загружаем SST-2 в качестве 1-го типа задач (где нужно одно предложение). Здесть обычная бинарная классификация на positive/negative. Смотрим на датасет, бьем его на треин и тест"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBn6ejxaokw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Вместо test-а возьмите valid, а valid сделай из train.\n",
        "\n",
        "# <YOUR CODE>\n",
        "train_pd = pd.read_csv('/content/data/SST-2/train.tsv', sep='\\t')\n",
        "test_pd = pd.read_csv('/content/data/SST-2/dev.tsv', sep='\\t')\n",
        "#test_pd = pd.read_csv('/content/data/SST-2/test.tsv', sep='\\t')\n",
        "# </YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfqFvvLFMM-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pd = train_pd[:int(len(train_pd)*0.97)]\n",
        "val_pd = train_pd[int(len(train_pd)*0.97):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gZYfZwaLcHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pd.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6RxAkcALzQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_pd.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ytLuxQfLiiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pd.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2CnhSU9pAQk",
        "colab_type": "text"
      },
      "source": [
        "`В качестве второго датасета берем QQP, где уже надо сравнить 2 предложения, чтобы определить, являются ли они дупликатами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyzfG-ROkdos",
        "colab_type": "code",
        "outputId": "9a5bc4ee-57a5-4399-81d7-ce29ccd4982a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Вместо test-а возьмите valid, а valid сделай из train.\n",
        "\n",
        "# <YOUR CODE>\n",
        "train_pd = pd.read_csv('/content/data/QQP/train.tsv', sep='\\t', error_bad_lines=False)\n",
        "test_pd = pd.read_csv('/content/data/QQP/dev.tsv', sep='\\t', error_bad_lines=False)\n",
        "#test_pd = pd.read_csv('/content/data/SST-2/test.tsv', sep='\\t')\n",
        "# </YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
            "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning:\n",
            "\n",
            "Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4M1OyzOl36B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pd.dropna(inplace=True)\n",
        "test_pd.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pemzmasBkvn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pd = train_pd[:int(len(train_pd)*0.89)]\n",
        "val_pd = train_pd[int(len(train_pd)*0.89):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClTdXoh4lNEs",
        "colab_type": "code",
        "outputId": "246b4127-0de3-4f6c-8857-444e7d927c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_pd.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133273</td>\n",
              "      <td>213221</td>\n",
              "      <td>213222.0</td>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402555</td>\n",
              "      <td>536040</td>\n",
              "      <td>536041.0</td>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360472</td>\n",
              "      <td>364011</td>\n",
              "      <td>490273.0</td>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150662</td>\n",
              "      <td>155721</td>\n",
              "      <td>7256.0</td>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183004</td>\n",
              "      <td>279958</td>\n",
              "      <td>279959.0</td>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ... is_duplicate\n",
              "0  133273  ...          0.0\n",
              "1  402555  ...          1.0\n",
              "2  360472  ...          0.0\n",
              "3  150662  ...          1.0\n",
              "4  183004  ...          0.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK5iar5f8e_7",
        "colab_type": "text"
      },
      "source": [
        "Для начала рассмотрим важную часть обработки текста для трансфомера(и не только) – токенайзер.\n",
        "\n",
        "В качестве примера токенайзера воспользуемся внутренним из библиотеки transformers, обученным для BERT-а. Посмотрим, что он умеет."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3h53-DpofT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0BjZAx68v6T",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим, как происходит токенизация предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkvs3uQpsCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = \"Hide new secretions from the parental units.\"\n",
        "print(tokenizer.tokenize(test_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La_1q8Cj82e8",
        "colab_type": "text"
      },
      "source": [
        "Видно, что предложения разделяются не на слова, а подслова. Токены, которые надо объеденить в слова для получения \"нормального\" текста, выделены с помощью `##`. Посмотрим, как различаются коды токенов с этим символом и без него."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKd0SwME9bi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tokenizer.convert_tokens_to_ids(['ions']))\n",
        "print(tokenizer.convert_tokens_to_ids(['##ions']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5qZXD5Z-D5o",
        "colab_type": "text"
      },
      "source": [
        "Для токенизации предложений воспользуемся методом `encode`. Она принимает предложение как строку или список токенов**(!)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUZQ6tMNpsEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tokenizer.encode(test_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiVCb6RG-Yi2",
        "colab_type": "text"
      },
      "source": [
        "Добавились специальные токены впереди и сзади предложения. Посмотрим на весь список специальных токенов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AqoVIrktk4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tokenizer.special_tokens_map)\n",
        "print({i: j for i, j in zip(tokenizer.all_special_tokens, tokenizer.all_special_ids)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TA4XbeA-phM",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим, что ещё может делать токенайзер. Что требуется нам для обучения BERT-а: добавить паддинг, получить маску аттеншена и тип токенов. Попробуем сделать это самостоятельно и посмотрим, как это сделать с помощью токенайзера.\n",
        "\n",
        "Выбери два предложения из обучающей выборки. Получи их токены с помощью метода `tokenize`. Объедени списки токенов так, чтобы модель могла различать, что они от разных предложений. \n",
        "\n",
        "(Подсказка: на семинаре была картинка с эмбеддингами. Она может подсказать, что надо изменить в токенах предложения) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4esxYXTipsG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# <YOUR CODE>\n",
        "s1, s2 = train_pd.sentence[1], train_pd.sentence[0]\n",
        "tokenized_s1, tokenized_s2 = tokenizer.tokenize(s1), tokenizer.tokenize(s2)\n",
        "s_union = tokenized_s1+['[SEP]']+tokenized_s2\n",
        "# </YOUR CODE>\n",
        "\n",
        "# <DON'T TOUCH THIS!>\n",
        "assert tokenizer.encode(s_union) == tokenizer.encode(s1, s2), \"Not equal\"\n",
        "# </DON'T TOUCH THIS!>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k6nrFRHBJBl",
        "colab_type": "text"
      },
      "source": [
        "Теперь надо добавь нулей в полученный список чисел, чтобы они легко складывались в батчи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY-xd0_qp9rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# <YOUR CODE>\n",
        "encoded_full = tokenizer.encode(s_union)+[0 for i in range((max_seq_length - len(s_union)-2))]\n",
        "\n",
        "# <DON'T TOUCH THIS!>\n",
        "encoded_correct = tokenizer.encode(s1, s2, max_length=max_seq_length, pad_to_max_length=True)\n",
        "assert len(encoded_full) == len(encoded_correct), \"Different length\"\n",
        "assert encoded_full == encoded_correct, \"Not equal\"\n",
        "# </DON'T TOUCH THIS!>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd5yNVukBZuC",
        "colab_type": "text"
      },
      "source": [
        "В модель также надо кинуть маску для механизма внимания и тип предложения для каждого токена. Сделай их."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hiljf3_vQ75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# <YOUR CODE>\n",
        "token_type_ids = [0 for i in range(10)] + [1 for i in range(10)] + [0 for i in range(108)]\n",
        "attention_mask = [1  if i!=0 else 0 for i in encoded_full]\n",
        "# </YOUR CODE>\n",
        "\n",
        "# <DON'T TOUCH THIS!>\n",
        "encoded_plus = tokenizer.encode_plus(train_pd['sentence'][0], text_pair=train_pd['sentence'][1], max_length=max_seq_length, pad_to_max_length=True)\n",
        "assert len(token_type_ids) == len(encoded_plus['token_type_ids']), \"Different length in token_type_ids\"\n",
        "assert token_type_ids == encoded_plus['token_type_ids'], \"Not equal token_type_ids\"\n",
        "assert len(attention_mask) == len(encoded_plus['attention_mask']), \"Different length in attention_mask\"\n",
        "assert attention_mask == encoded_plus['attention_mask'], \"Not equal attention_mask\"\n",
        "# </DON'T TOUCH THIS!>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxruIU08CEgg",
        "colab_type": "text"
      },
      "source": [
        "Как видно из тестов, все нужные для обработки текста для BERT-а вещи может делать токенизатор из `transformers`. Но не все токенизаторы настолько функциональны. Их (почти)полный список:\n",
        "- [Sentence Piece](https://github.com/google/sentencepiece/)\n",
        "- [fastBPE](https://github.com/glample/fastBPE)\n",
        "- [Hugging Face Tokenizers](https://github.com/huggingface/tokenizers)\n",
        "- [YouTokenToMe](https://github.com/VKCOM/YouTokenToMe)\n",
        "\n",
        "Их сравнивают [здесь](https://github.com/VKCOM/YouTokenToMe/blob/master/benchmark.md) или [здесь](https://towardsdatascience.com/a-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6). Также специальные токенайзеры, которые специализируются на \"незападные\" языки. Но не будем на них останавливаться.\n",
        "\n",
        "Теперь ты знаешь достаточно, чтобы написать обработчик данных. Что надо сделать: получить из данных предложения, закодировать их, получить аттенш маску и тип токенов, не забыть про таргет. \n",
        "\n",
        "P.S. Есть более быстрая версия токенизатора для BERT внутри `transformers`, `BertTokenizerFast`. \n",
        "\n",
        "P.S.S. Теперь надо использовать только функционал токенайзера для кодирования предложений, без велосипедов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y-wgeHHokz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, b=False):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if b:\n",
        "          self.encoded_plus = [tokenizer.encode_plus(data['question1'].iloc[i], text_pair = data['question2'].iloc[i], max_length=max_seq_length, pad_to_max_length=True) for i in range(len(data))]\n",
        "\n",
        "        else:\n",
        "          self.encoded_plus = [tokenizer.encode_plus(data['sentence'].iloc[i], max_length=max_seq_length, pad_to_max_length=True) for i in range(len(data))]\n",
        "\n",
        "        # <YOUR CODE>\n",
        "        self.input_ids = np.array([i['input_ids'] for i in self.encoded_plus])\n",
        "        self.attention_mask = np.array([i['attention_mask'] for i in self.encoded_plus])\n",
        "        self.token_type_ids = np.array([i['token_type_ids'] for i in self.encoded_plus])\n",
        "        if b:\n",
        "          self.targets = data['is_duplicate'].values\n",
        "        else:\n",
        "          self.targets = data['label'].values\n",
        "        # </YOUR CODE>\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'token_type_ids': self.token_type_ids[idx],\n",
        "            'targets': int(self.targets[idx])\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w46bGSo6lOFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_model_name = \"google/bert_uncased_L-6_H-256_A-4\"\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(pretrained_model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFVoCAkiFGJt",
        "colab_type": "text"
      },
      "source": [
        "Воспользуйтесь семинаром и построй модель для классификации предложений.\n",
        "\n",
        "(Подсказка: весь код BERT-а из семинара доступен из библиотеки `transformers`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF0XFH9INVvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# models to try\n",
        "# \"google/bert_uncased_L-2_H-128_A-2\" \"google/bert_uncased_L-4_H-128_A-2 \" \"google/bert_uncased_L-2_H-256_A-4 \"\n",
        "# 'google/bert_uncased_L-4_H-256_A-4' 'google/bert_uncased_L-6_H-256_A-4 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sys6Q11Q06FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel as bertik"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fXEEAWBmd10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = bert.from_pretrained(pretrained_model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa6coCLFFSZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, pretrained_model_name: str, num_labels: int, dropout=0.25):\n",
        "        super().__init__()\n",
        "\n",
        "        # <YOUR CODE>\n",
        "        self.bert = bertik.from_pretrained(pretrained_model_name)\n",
        "\n",
        "        self.classifier = nn.Linear(self.bert.config.to_dict()['hidden_size'], num_labels)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # </YOUR CODE>\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "        assert attention_mask is not None, \"attention mask is none\"\n",
        "        \n",
        "        bert_output = self.bert(input_ids=input_ids,\n",
        "                                attention_mask=attention_mask,\n",
        "                                token_type_ids=token_type_ids)\n",
        "       \n",
        "        #<YOUR CODE>\n",
        "        hidden_state = bert_output[0]  # (bs, seq_len, dim)\n",
        "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
        "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
        "        logits = self.classifier(pooled_output)  # (bs, dim)\n",
        "        \n",
        "        \n",
        "        #</YOUR CODE>\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI9IMsE0G1gh",
        "colab_type": "text"
      },
      "source": [
        "Выбери из [списка](https://huggingface.co/models?search=google%2Fbert_) несколько моделей, которые ты будешь обучать. Сравни их качество на выбранных датасетах. \n",
        "\n",
        "Лучше всего будет выбрать одну основную конфигурацию, и другие с небольшим изменением. Например, пройтись по такой сетке: `{'layers': [2, 4], 'num_heads': [2, 4]}`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-22wBwrFMob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# <YOUR CODE>\n",
        "num_labels = 2\n",
        "pretrained_model_name = 'google/bert_uncased_L-6_H-256_A-4'#\"bert-base-uncased\"\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(pretrained_model_name)\n",
        "model = BertForSequenceClassification(pretrained_model_name, num_labels=num_labels)\n",
        "# </YOUR CODE>\n",
        "\n",
        "model.to(device)\n",
        "print(\"Success!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRJy5hEWpNWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCL7wstMczw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "\n",
        "# <YOUR CODE>\n",
        "train_dataset = TextClassificationDataset(train_pd,  tokenizer, b=True)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "valid_dataset = TextClassificationDataset(val_pd,  tokenizer, b=True)\n",
        "valid_sampler = RandomSampler(valid_dataset)\n",
        "valid_dataloader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=batch_size)\n",
        "\n",
        "test_dataset = TextClassificationDataset(test_pd,  tokenizer, b=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_dataloader,\n",
        "    \"valid\": valid_dataloader    \n",
        "}\n",
        "# </YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VsyoAmwjnb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 404\n",
        "set_global_seed(seed)\n",
        "prepare_cudnn(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "38ojXge_Hy71",
        "colab": {}
      },
      "source": [
        "# Гиперпараметры для обучения модели. Подбери нужные для каждой модели.\n",
        "\n",
        "epochs = 5\n",
        "lr = 1e-5\n",
        "warmup_steps = len(train_dataloader) // 2\n",
        "t_total = len(train_dataloader) * epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3TVwcWzH1ok",
        "colab_type": "text"
      },
      "source": [
        "Добавь Loss, Optimizer и Scheduler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mifqwFYdjnWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_grouped_parameters = [\n",
        "    {\"params\": [p for n, p in model.named_parameters()], \"weight_decay\": 0.0},\n",
        "]\n",
        "\n",
        "# <YOUR CODE>\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
        ")\n",
        "# </YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbbWyPiE7MgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = 'logs/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTXx8X69IClJ",
        "colab_type": "text"
      },
      "source": [
        "Для обучения модели воспользуемся библиотекой `catalyst`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFZ9z53VE5tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runner = SupervisedRunner(\n",
        "    input_key=(\n",
        "        \"input_ids\",\n",
        "        \"attention_mask\",\n",
        "        \"token_type_ids\"\n",
        "    )\n",
        ")\n",
        "\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders= dataloaders,\n",
        "    callbacks=[\n",
        "        AccuracyCallback(num_classes=num_labels),\n",
        "        SchedulerCallback(mode='batch'),\n",
        "        \n",
        "    ],\n",
        "    logdir=log_dir,\n",
        "    num_epochs= epochs,\n",
        "    verbose=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnaWaUODPphg",
        "colab_type": "text"
      },
      "source": [
        "# SST-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvRJUJ6TPq7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgpYCLXkPrVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to get a test prediction\n",
        "y_pred = []\n",
        "for batch in test_dataloader:\n",
        "  logits = runner.predict_batch(batch)\n",
        "  \n",
        "  y_pred.extend(logits['logits'].cpu().argmax(axis=1).tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCE5ZkSHZPc8",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-2_H-128_A-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCmxgcoWTzD4",
        "colab_type": "code",
        "outputId": "7788b416-f99a-4450-d429-518a388d33b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #0.8096330275229358\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #0.8139013452914797"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 80.96330275229357 %\n",
            "Test f1: 81.39013452914797 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSM_PL7nUJ9f",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-4_H-128_A-2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omix8FOrUkvx",
        "colab_type": "code",
        "outputId": "99ccb1ff-62be-45fc-b94e-d736c04cc656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #79.81651376146789 %\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #80.22471910112358 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 79.81651376146789 %\n",
            "Test f1: 80.22471910112358 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO4aKHScVvzs",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-2_H-256_A-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dEgXKrlVv8E",
        "colab_type": "code",
        "outputId": "d495372a-6a7d-453d-b64c-fe1d062d298a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #82.11009174311926\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #82.47191011235955 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 82.11009174311926 %\n",
            "Test f1: 82.47191011235955 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU50rjM3XC4W",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-4_H-256_A-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7a-ieerXEoH",
        "colab_type": "code",
        "outputId": "08794bbb-24e3-4d1f-9f24-f55f4eab6164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #84.17431192660551 %\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #84.56375838926175 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 84.17431192660551 %\n",
            "Test f1: 84.56375838926175 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crTAC7wyZa7r",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-6_H-256_A-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4NGOABxZc1z",
        "colab_type": "code",
        "outputId": "6dcb42d4-6d9a-4ebb-d0d4-6c83a2ba55cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #86.0091743119266\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #86.5934065934066 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 86.0091743119266 %\n",
            "Test f1: 86.5934065934066 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvpBpp5fnxZm",
        "colab_type": "text"
      },
      "source": [
        "QQP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqcPw-YfUoJx",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-2_H-128_A-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTRg9Z1Un1Li",
        "colab_type": "code",
        "outputId": "756674cd-b3c0-4faa-a857-1eff9badf5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #79.80728740927894 %\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #76.36827458256029 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 79.80728740927894 %\n",
            "Test f1: 76.36827458256029 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psqeo1T9sJ5H",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-4_H-128_A-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD44ThTGsLEa",
        "colab_type": "code",
        "outputId": "b2a6b3ac-6b43-4afb-f9da-c8290029c5d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #82.76981001213743 %\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #78.5599802737024 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 82.76981001213743 %\n",
            "Test f1: 78.5599802737024 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJIWPbW3yZbp",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-2_H-256_A-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmNdIFgDyYtb",
        "colab_type": "code",
        "outputId": "50f2c74b-11ec-4cbd-c305-3a7613e0f592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #83.94392014069506\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #79.35011150047787 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 83.94392014069506 %\n",
            "Test f1: 79.35011150047787 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5_BnNxE4V3p",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-4_H-256_A-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SXYbTVM4W0n",
        "colab_type": "code",
        "outputId": "ffb07ea4-2277-4b41-978f-aa33896c8357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #85.62086646355057 %\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #81.56967330221924 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 85.62086646355057 %\n",
            "Test f1: 81.56967330221924 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5U1SPuVBl2q",
        "colab_type": "text"
      },
      "source": [
        "google/bert_uncased_L-6_H-256_A-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XArTrhmSBlbM",
        "colab_type": "code",
        "outputId": "adfd9eec-d51c-4acf-94b8-9d0b0a3027f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Test accuracy:',accuracy_score(test_dataset.targets, y_pred)*100, \"%\") #86.00975948081543 %\n",
        "print('Test f1:',f1_score(test_dataset.targets, y_pred)*100, \"%\") #81.66233766233766 %"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 86.00975948081543 %\n",
            "Test f1: 81.66233766233766 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6kn46c5iGq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame(list(zip([80.96, 79.81, 82.11, 84.17, 86.01], [79.81, 82.77, 83.94, 85.62, 86.01, 81.66],\n",
        "[81.39, 80.22, 82.47, 84.56, 86.59], [76.37, 78.56, 79.36, 81.57, 81.66])), columns = ['SST-2 acc', 'QQP acc', 'SST-2 f1', 'QQP f1'], index=['google/bert_uncased_L-2_H-128_A-2', 'google/bert_uncased_L-4_H-128_A-2', 'google/bert_uncased_L-2_H-256_A-4','google/bert_uncased_L-4_H-256_A-4', 'google/bert_uncased_L-6_H-256_A-4'])                                                                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViZwMS2pIkBv",
        "colab_type": "text"
      },
      "source": [
        "Ииии отчет!\n",
        "\n",
        "Напиши внизу небольшой отчет о проделанной работе. Ожидается сравнение результатов модели с разным количеством голов/слоев на разных датасетах на `test`. Если для оценки качества на датасете используется необычная метрика(не Accuracy или F1), то можно использовать один из них. Было бы круто, если бы вычислялась нужная метрика и она использовалась в отчете."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGbBbRGufkZ8",
        "colab_type": "code",
        "outputId": "246e0406-828c-4e61-c7e2-cb98a5f64fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SST-2 acc</th>\n",
              "      <th>QQP acc</th>\n",
              "      <th>SST-2 f1</th>\n",
              "      <th>QQP f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>google/bert_uncased_L-2_H-128_A-2</th>\n",
              "      <td>80.96</td>\n",
              "      <td>79.81</td>\n",
              "      <td>81.39</td>\n",
              "      <td>76.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>google/bert_uncased_L-4_H-128_A-2</th>\n",
              "      <td>79.81</td>\n",
              "      <td>82.77</td>\n",
              "      <td>80.22</td>\n",
              "      <td>78.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>google/bert_uncased_L-2_H-256_A-4</th>\n",
              "      <td>82.11</td>\n",
              "      <td>83.94</td>\n",
              "      <td>82.47</td>\n",
              "      <td>79.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>google/bert_uncased_L-4_H-256_A-4</th>\n",
              "      <td>84.17</td>\n",
              "      <td>85.62</td>\n",
              "      <td>84.56</td>\n",
              "      <td>81.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>google/bert_uncased_L-6_H-256_A-4</th>\n",
              "      <td>86.01</td>\n",
              "      <td>86.01</td>\n",
              "      <td>86.59</td>\n",
              "      <td>81.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   SST-2 acc  QQP acc  SST-2 f1  QQP f1\n",
              "google/bert_uncased_L-2_H-128_A-2      80.96    79.81     81.39   76.37\n",
              "google/bert_uncased_L-4_H-128_A-2      79.81    82.77     80.22   78.56\n",
              "google/bert_uncased_L-2_H-256_A-4      82.11    83.94     82.47   79.36\n",
              "google/bert_uncased_L-4_H-256_A-4      84.17    85.62     84.56   81.57\n",
              "google/bert_uncased_L-6_H-256_A-4      86.01    86.01     86.59   81.66"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPkOqg-Osf-c",
        "colab_type": "text"
      },
      "source": [
        " Итак, все результаты эксериментов представлены в таблице res. Для сравнения моделей были использованы датасеты SST-2 и QQP. В первом случае задача сентимент классификации (positive/negative) с соответствующими лейблами 1/0, во втором случае также бинарная классификация, но уже для пары предложений нужно определить, являются ли они дубликатами по значению или же нет (1/0). В качестве метрик использованы классические для классификации accuracy и f1. Все модели обучались 5 эпох с шагом 1e-5. и. scheduler. Использованные модели: google/bert_uncased_L-2_H-128_A-2, google/bert_uncased_L-4_H-128_A-2, google/bert_uncased_L-2_H-256_A-4, google/bert_uncased_L-4_H-256_A-4, google/bert_uncased_L-6_H-256_A-4\t8. Таким образом, рассматривались модели с [2, 4, 6] слоями, [128, 256] размерностью вектора скрытого состояния и [2, 4] аттеншн головами.  По таблице отчетливо прослеживается, что чем более мощная и сложная модель - тем лучших результатов в средем она достигает. Хотя есть и  исключение,  Берт с 4 слоями и hidden 128 уступает аналогичному Берту с 2 слоями по accuracy на обеих задачах. Однако во всех остальных случаях данная закономерность не нарушается и самые высокие показатели для обоих датасетов по обеим метрикам продемонстрировала модель google/bert_uncased_L-6_H-256_A-4, которая имеет целых 6 слоев, hidden 256 и 4 головы аттешна."
      ]
    }
  ]
}